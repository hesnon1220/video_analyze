#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç³»çµ±åˆå§‹åŒ–å’Œå„ªåŒ–æ¸¬è©¦è…³æœ¬
è‡ªå‹•ä¸‹è¼‰æ¨¡å‹ã€è¨­ç½®GPUåŠ é€Ÿã€æ¸¬è©¦æ‰€æœ‰å„ªåŒ–åŠŸèƒ½
"""

import sys
import os
from pathlib import Path
import logging
import time
import json

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

from utils import setup_logger, load_config, save_json
from utils.hardware_manager import initialize_hardware_and_models

def setup_system():
    """å®Œæ•´ç³»çµ±è¨­ç½®"""
    print("ğŸš€ é–‹å§‹ç³»çµ±åˆå§‹åŒ–å’Œå„ªåŒ–è¨­ç½®...")
    
    # è¨­å®šæ—¥èªŒ
    logger = setup_logger('system_setup', level=logging.INFO)
    
    # 1. åˆå§‹åŒ–ç¡¬é«”å’Œæ¨¡å‹
    print("\n" + "=" * 60)
    print("æ­¥é©Ÿ1: åˆå§‹åŒ–ç¡¬é«”å’Œä¸‹è¼‰æ¨¡å‹")
    print("=" * 60)
    
    try:
        hw_manager, model_manager = initialize_hardware_and_models()
        print("âœ… ç¡¬é«”å’Œæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
        # é¡¯ç¤ºç¡¬é«”è³‡è¨Š
        hw_info = hw_manager.get_device_info()
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {hw_info['device']}")
        if hw_info['device'] == 'cuda':
            print(f"   GPU: {hw_info.get('gpu_name', 'Unknown')}")
            print(f"   GPUè¨˜æ†¶é«”: {hw_info.get('gpu_memory_total', 0):.1f}GB")
        
        # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
        model_info = model_manager.get_model_info()
        print(f"ğŸ“ æ¨¡å‹ç›®éŒ„: {model_info['model_directory']}")
        print(f"ğŸ¯ å¯ç”¨YOLOæ¨¡å‹: {len(model_info['yolo_models_available'])}")
        for model in model_info['yolo_models_available']:
            print(f"   - {model['name']} ({model['size_mb']:.1f}MB)")
        print(f"ğŸµ Demucsæº–å‚™å°±ç·’: {'âœ…' if model_info['demucs_ready'] else 'âŒ'}")
        
    except Exception as e:
        print(f"âŒ ç¡¬é«”å’Œæ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
        return False
    
    # 2. æ¸¬è©¦GPUåŠ é€ŸYOLO
    print("\n" + "=" * 60)
    print("æ­¥é©Ÿ2: æ¸¬è©¦GPUåŠ é€ŸYOLOæª¢æ¸¬")
    print("=" * 60)
    
    try:
        config = load_config('config.yaml')
        from image_analysis import FeatureExtractor
        
        feature_extractor = FeatureExtractor(config['image_analysis'])
        
        # æ‰¾æ¸¬è©¦å½±ç‰‡
        test_videos = [
            r"F:\work\video_analyze\test_1.mp4",
            r"F:\work\video_analyze\test.mp4"
        ]
        
        test_video = None
        for video_path in test_videos:
            if Path(video_path).exists():
                test_video = video_path
                break
        
        if test_video:
            print(f"ğŸ¬ ä½¿ç”¨æ¸¬è©¦å½±ç‰‡: {Path(test_video).name}")
            
            # æ¸¬è©¦åŸºæœ¬åŠŸèƒ½
            import cv2
            cap = cv2.VideoCapture(test_video)
            ret, frame = cap.read()
            cap.release()
            
            if ret:
                print("â±ï¸  åŸ·è¡ŒYOLOæª¢æ¸¬æ¸¬è©¦...")
                start_time = time.time()
                
                # æ¸¬è©¦ç‰¹å¾µæå–
                basic_features = feature_extractor.extract_basic_features(frame)
                yolo_features = feature_extractor.extract_yolo_features(frame)
                
                end_time = time.time()
                
                print(f"âœ… YOLOæª¢æ¸¬å®Œæˆï¼Œè€—æ™‚: {end_time - start_time:.2f}ç§’")
                print(f"   æª¢æ¸¬åˆ°ç‰©é«”: {yolo_features.get('total_objects', 0)}å€‹")
                print(f"   äººç‰©æ•¸é‡: {yolo_features.get('person_count', 0)}äºº")
                print(f"   ä½¿ç”¨è¨­å‚™: {feature_extractor.device}")
                
                if yolo_features.get('object_counts'):
                    top_objects = sorted(yolo_features['object_counts'].items(), 
                                       key=lambda x: x[1], reverse=True)[:3]
                    print(f"   ä¸»è¦ç‰©é«”: {', '.join([f'{obj}({count})' for obj, count in top_objects])}")
            else:
                print("âš ï¸  ç„¡æ³•è®€å–æ¸¬è©¦å½±ç‰‡å¹€")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°æ¸¬è©¦å½±ç‰‡ï¼Œè·³éYOLOæ¸¬è©¦")
        
    except Exception as e:
        print(f"âŒ YOLOæ¸¬è©¦å¤±æ•—: {e}")
    
    # 3. æ¸¬è©¦GPUåŠ é€ŸéŸ³æºåˆ†é›¢
    print("\n" + "=" * 60)
    print("æ­¥é©Ÿ3: æ¸¬è©¦GPUåŠ é€ŸéŸ³æºåˆ†é›¢")
    print("=" * 60)
    
    try:
        from music_processing import AudioSeparator
        
        audio_separator = AudioSeparator(config['music_processing'])
        
        # æ‰¾æ¸¬è©¦éŸ³é »
        test_audios = [
            r"F:\work\video_analyze\data\test.mp3",
            r"F:\work\video_analyze\data\test.wav"
        ]
        
        test_audio = None
        for audio_path in test_audios:
            if Path(audio_path).exists():
                test_audio = audio_path
                break
        
        if test_audio:
            print(f"ğŸµ ä½¿ç”¨æ¸¬è©¦éŸ³é »: {Path(test_audio).name}")
            print(f"   ä½¿ç”¨è¨­å‚™: {audio_separator.device}")
            print(f"   æ¨¡å‹: {audio_separator.model_name}")
            
            # æ¸¬è©¦åˆ†é›¢ï¼ˆä½¿ç”¨çŸ­éŸ³é »é¿å…è€—æ™‚éé•·ï¼‰
            if audio_separator.model is not None:
                print("â±ï¸  åŸ·è¡ŒéŸ³æºåˆ†é›¢æ¸¬è©¦...")
                start_time = time.time()
                
                # ç°¡å–®æ¸¬è©¦æ¨¡å‹è¼‰å…¥
                print("âœ… Demucsæ¨¡å‹è¼‰å…¥æˆåŠŸ")
                print("   (å®Œæ•´åˆ†é›¢æ¸¬è©¦éœ€è¦è¼ƒé•·æ™‚é–“ï¼Œå·²è·³é)")
                
            else:
                print("âš ï¸  Demucs APIä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨å‘½ä»¤åˆ—æ–¹å¼")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°æ¸¬è©¦éŸ³é »ï¼Œè·³ééŸ³æºåˆ†é›¢æ¸¬è©¦")
    
    except Exception as e:
        print(f"âŒ éŸ³æºåˆ†é›¢æ¸¬è©¦å¤±æ•—: {e}")
    
    # 4. æ€§èƒ½å„ªåŒ–å»ºè­°
    print("\n" + "=" * 60)
    print("æ­¥é©Ÿ4: æ€§èƒ½å„ªåŒ–å»ºè­°")
    print("=" * 60)
    
    recommendations = []
    
    # GPUå»ºè­°
    if hw_info['device'] == 'cuda':
        gpu_memory = hw_info.get('gpu_memory_total', 0)
        if gpu_memory > 8:
            recommendations.append("âœ… GPUè¨˜æ†¶é«”å……è¶³ï¼Œå¯ä»¥ä½¿ç”¨è¼ƒå¤§çš„YOLOæ¨¡å‹ (yolov8m æˆ– yolov8l)")
            recommendations.append("âœ… å¯ä»¥å¢åŠ batch_sizeåˆ°16ä»¥æå‡è™•ç†é€Ÿåº¦")
        elif gpu_memory > 4:
            recommendations.append("âœ… GPUè¨˜æ†¶é«”é©ä¸­ï¼Œå»ºè­°ä½¿ç”¨ yolov8s æ¨¡å‹")
            recommendations.append("âœ… batch_sizeè¨­ç‚º8-12è¼ƒç‚ºåˆé©")
        else:
            recommendations.append("âš ï¸  GPUè¨˜æ†¶é«”è¼ƒå°ï¼Œå»ºè­°ä½¿ç”¨ yolov8n æ¨¡å‹")
            recommendations.append("âš ï¸  batch_sizeå»ºè­°è¨­ç‚º4-6")
    else:
        recommendations.append("âš ï¸  æœªæª¢æ¸¬åˆ°GPUï¼Œè™•ç†é€Ÿåº¦æœƒè¼ƒæ…¢")
        recommendations.append("ğŸ’¡ å»ºè­°å®‰è£CUDAä»¥ç²å¾—GPUåŠ é€Ÿ")
        recommendations.append("ğŸ’¡ CPUæ¨¡å¼ä¸‹å»ºè­°é™ä½å½±ç‰‡è§£æåº¦ä»¥æå‡é€Ÿåº¦")
    
    # æ¨¡å‹å»ºè­°
    if len(model_info['yolo_models_available']) == 0:
        recommendations.append("âŒ æœªæ‰¾åˆ°YOLOæ¨¡å‹ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·š")
    
    if not model_info['demucs_ready']:
        recommendations.append("âŒ Demucsæœªå°±ç·’ï¼Œè«‹æª¢æŸ¥å¥—ä»¶å®‰è£")
    
    # é…ç½®å»ºè­°
    recommendations.append("ğŸ’¡ å»ºè­°æ ¹æ“šå½±ç‰‡é¡å‹èª¿æ•´confidenceé–¾å€¼")
    recommendations.append("ğŸ’¡ äººç‰©è¼ƒå¤šçš„å½±ç‰‡å¯è¨­confidence=0.3")
    recommendations.append("ğŸ’¡ é¢¨æ™¯å½±ç‰‡å¯è¨­confidence=0.5")
    
    print("ğŸ“Š æ€§èƒ½å„ªåŒ–å»ºè­°:")
    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. {rec}")
    
    # 5. ç”Ÿæˆé…ç½®æ‘˜è¦
    print("\n" + "=" * 60)
    print("æ­¥é©Ÿ5: ç”Ÿæˆç³»çµ±é…ç½®æ‘˜è¦")
    print("=" * 60)
    
    system_summary = {
        "setup_date": time.strftime("%Y-%m-%d %H:%M:%S"),
        "hardware": hw_info,
        "models": model_info,
        "optimization_status": {
            "gpu_acceleration": hw_info['device'] == 'cuda',
            "yolo_ready": len(model_info['yolo_models_available']) > 0,
            "demucs_ready": model_info['demucs_ready'],
            "batch_processing": True
        },
        "recommendations": recommendations,
        "config_optimizations": {
            "suggested_model_size": "s" if hw_info['device'] == 'cuda' else "n",
            "suggested_batch_size": 8 if hw_info['device'] == 'cuda' else 4,
            "suggested_confidence": 0.4,
            "suggested_gpu_memory_fraction": 0.8
        }
    }
    
    # å„²å­˜é…ç½®æ‘˜è¦
    save_json(system_summary, "output/system_setup_summary.json")
    print("âœ… ç³»çµ±é…ç½®æ‘˜è¦å·²å„²å­˜è‡³: output/system_setup_summary.json")
    
    # 6. æ›´æ–°é…ç½®æª”æ¡ˆå»ºè­°
    print("\n" + "=" * 60)
    print("æ­¥é©Ÿ6: é…ç½®å„ªåŒ–å»ºè­°")
    print("=" * 60)
    
    config_updates = {}
    
    if hw_info['device'] == 'cuda':
        config_updates.update({
            'hardware.device': 'cuda',
            'image_analysis.yolo.device': 'cuda',
            'music_processing.demucs.device': 'cuda',
            'performance.batch_size': 8 if hw_info.get('gpu_memory_total', 0) > 6 else 4
        })
    
    if config_updates:
        print("å»ºè­°çš„é…ç½®æ›´æ–°:")
        for key, value in config_updates.items():
            print(f"   {key}: {value}")
    
    print("\nğŸ‰ ç³»çµ±åˆå§‹åŒ–å’Œå„ªåŒ–è¨­ç½®å®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. åŸ·è¡Œ test_end_to_end.py é€²è¡Œå®Œæ•´æ¸¬è©¦")
    print("2. æ ¹æ“šå»ºè­°èª¿æ•´ config.yaml é…ç½®")
    print("3. é–‹å§‹ä½¿ç”¨ main.py è™•ç†æ‚¨çš„å½±ç‰‡")
    
    return True

if __name__ == "__main__":
    success = setup_system()
    if not success:
        sys.exit(1)