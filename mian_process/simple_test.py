#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç°¡åŒ–ç‰ˆä¸»ç¨‹å¼ - é¿å…MoviePyå•é¡Œï¼Œå°ˆæ³¨æ¸¬è©¦æ ¸å¿ƒåŠŸèƒ½
"""

import os
import sys
from pathlib import Path

# ä¿®å¾©OpenMPè¡çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ['OMP_NUM_THREADS'] = '4'

import argparse
sys.path.append(str(Path(__file__).parent))

from utils import setup_logger, load_config, save_json
from image_analysis.scene_detector import SceneDetector
from image_analysis.feature_extractor import FeatureExtractor
from music_processing.audio_separator import AudioSeparator
from music_processing.rhythm_analyzer import RhythmAnalyzer

def main():
    """ç°¡åŒ–ç‰ˆä¸»ç¨‹å¼ - åªæ¸¬è©¦åˆ†æåŠŸèƒ½ï¼Œä¸é€²è¡Œå½±ç‰‡åˆæˆ"""
    parser = argparse.ArgumentParser(description='è‡ªå‹•å‰ªè¼¯å½±ç‰‡ç”Ÿæˆç³»çµ± - ç°¡åŒ–æ¸¬è©¦ç‰ˆ')
    parser.add_argument('--input', '--video', type=str, required=True, help='è¼¸å…¥å½±ç‰‡è·¯å¾‘')
    parser.add_argument('--audio', type=str, required=True, help='è¼¸å…¥éŸ³æ¨‚è·¯å¾‘')
    parser.add_argument('--config', type=str, default='config.yaml', help='é…ç½®æª”æ¡ˆè·¯å¾‘')
    
    args = parser.parse_args()
    
    # è¼‰å…¥é…ç½®
    config = load_config(args.config)
    
    # è¨­å®šæ—¥èªŒ
    log_dir = config.get('paths', {}).get('log_dir', '../logs')
    logger = setup_logger('simple_test', log_dir)
    
    print("ğŸš€ å•Ÿå‹•ç°¡åŒ–ç‰ˆå½±ç‰‡åˆ†æç³»çµ±")
    logger.info("ğŸš€ å•Ÿå‹•ç°¡åŒ–ç‰ˆå½±ç‰‡åˆ†æç³»çµ±")
    logger.info(f"ğŸ“¹ è¼¸å…¥å½±ç‰‡: {args.input}")
    logger.info(f"ğŸµ è¼¸å…¥éŸ³æ¨‚: {args.audio}")
    
    # æª¢æŸ¥è¼¸å…¥æ–‡ä»¶
    video_path = Path(args.input)
    audio_path = Path(args.audio)
    
    if not video_path.exists():
        print(f"âŒ å½±ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return False
    
    if not audio_path.exists():
        print(f"âŒ éŸ³é »æ–‡ä»¶ä¸å­˜åœ¨: {args.audio}")
        return False
    
    print(f"âœ… æ–‡ä»¶æª¢æŸ¥é€šé")
    print(f"ğŸ“¹ å½±ç‰‡å¤§å°: {video_path.stat().st_size / (1024*1024):.2f} MB")
    print(f"ğŸµ éŸ³é »å¤§å°: {audio_path.stat().st_size / (1024*1024):.2f} MB")
    
    results = {
        'input_files': {
            'video': str(video_path),
            'audio': str(audio_path),
            'video_size_mb': round(video_path.stat().st_size / (1024*1024), 2),
            'audio_size_mb': round(audio_path.stat().st_size / (1024*1024), 2)
        }
    }
    
    try:
        # æ­¥é©Ÿ1: å½±åƒåˆ†æ
        print("\nğŸ” æ­¥é©Ÿ1: å½±åƒåˆ†æ")
        print("-" * 40)
        
        scene_detector = SceneDetector(config['image_analysis'])
        scenes = scene_detector.detect_scenes(str(video_path))
        print(f"âœ… å ´æ™¯æª¢æ¸¬å®Œæˆ: {len(scenes)} å€‹å ´æ™¯")
        
        # åªåˆ†æå‰10å€‹å ´æ™¯ä¾†ç¯€çœæ™‚é–“
        scenes_to_analyze = scenes[:10] if len(scenes) > 10 else scenes
        print(f"ğŸ“Š åˆ†æå‰ {len(scenes_to_analyze)} å€‹å ´æ™¯çš„ç‰¹å¾µ")
        
        feature_extractor = FeatureExtractor(config['image_analysis'])
        features = feature_extractor.extract_features(str(video_path), scenes_to_analyze)
        print(f"âœ… ç‰¹å¾µæå–å®Œæˆ: {len(features)} å€‹å ´æ™¯")
        
        results['image_analysis'] = {
            'total_scenes': len(scenes),
            'analyzed_scenes': len(features),
            'scenes_summary': [
                {
                    'id': scene.get('id', i),
                    'start_time': scene.get('start_time', 0),
                    'duration': scene.get('duration', 0),
                    'analysis': scene.get('analysis', {})
                }
                for i, scene in enumerate(features[:5])  # åªä¿å­˜å‰5å€‹å ´æ™¯çš„æ‘˜è¦
            ]
        }
        
        # æ­¥é©Ÿ2: éŸ³æ¨‚è™•ç†
        print("\nğŸµ æ­¥é©Ÿ2: éŸ³æ¨‚è™•ç†")
        print("-" * 40)
        
        # ç¯€å¥åˆ†æ
        rhythm_analyzer = RhythmAnalyzer(config['music_processing'])
        rhythm_data = rhythm_analyzer.analyze(str(audio_path))
        bpm = rhythm_data.get('bpm', 'Unknown')
        beat_count = len(rhythm_data.get('tempo', {}).get('beat_times', []))
        print(f"âœ… ç¯€æ‹åˆ†æå®Œæˆ: BPM={bpm}, ç¯€æ‹é»={beat_count}å€‹")
        
        # éŸ³æºåˆ†é›¢æ¸¬è©¦ï¼ˆå¯é¸ï¼‰
        try:
            audio_separator = AudioSeparator(config['music_processing'])
            print("ğŸ¼ æ¸¬è©¦éŸ³æºåˆ†é›¢åŠŸèƒ½...")
            
            # åªåšç°¡å–®çš„æª¢æŸ¥ï¼Œä¸å¯¦éš›åˆ†é›¢
            if hasattr(audio_separator, 'model') and audio_separator.model:
                print("âœ… Demucsæ¨¡å‹å¯ç”¨")
                results['audio_separation'] = {'available': True, 'model': audio_separator.model_name}
            else:
                print("âš ï¸ Demucsæ¨¡å‹ä¸å¯ç”¨ï¼Œå°‡è·³ééŸ³æºåˆ†é›¢")
                results['audio_separation'] = {'available': False}
                
        except Exception as sep_error:
            print(f"âš ï¸ éŸ³æºåˆ†é›¢æ¸¬è©¦å¤±æ•—: {sep_error}")
            results['audio_separation'] = {'available': False, 'error': str(sep_error)}
        
        results['music_analysis'] = {
            'bpm': bpm,
            'beat_count': beat_count,
            'rhythm_data_keys': list(rhythm_data.keys())
        }
        
        # æ­¥é©Ÿ3: ç”Ÿæˆåˆ†æå ±å‘Š
        print("\nğŸ“Š æ­¥é©Ÿ3: ç”Ÿæˆåˆ†æå ±å‘Š")
        print("-" * 40)
        
        # è¨ˆç®—ä¸€äº›çµ±è¨ˆè³‡è¨Š
        if features:
            visual_appeals = [scene.get('analysis', {}).get('visual_appeal', 'unknown') for scene in features]
            scene_types = [scene.get('analysis', {}).get('scene_type', 'unknown') for scene in features]
            
            from collections import Counter
            appeal_counts = Counter(visual_appeals)
            type_counts = Counter(scene_types)
            
            results['statistics'] = {
                'visual_appeal_distribution': dict(appeal_counts),
                'scene_type_distribution': dict(type_counts),
                'avg_scene_duration': sum(s.get('duration', 0) for s in scenes) / len(scenes) if scenes else 0
            }
            
            print(f"ğŸ“ˆ è¦–è¦ºå¸å¼•åŠ›åˆ†ä½ˆ: {dict(appeal_counts)}")
            print(f"ğŸ“ˆ å ´æ™¯é¡å‹åˆ†ä½ˆ: {dict(type_counts)}")
        
        # ä¿å­˜çµæœ
        output_file = "output/simple_analysis_result.json"
        Path("output").mkdir(exist_ok=True)
        save_json(results, output_file)
        
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“ çµæœå·²ä¿å­˜åˆ°: {output_file}")
        print(f"ğŸ“Š ç¸½å ´æ™¯æ•¸: {len(scenes)}")
        print(f"ğŸµ éŸ³æ¨‚BPM: {bpm}")
        print(f"âš¡ ç³»çµ±åŠŸèƒ½: æ­£å¸¸é‹è¡Œ")
        
        return True
        
    except Exception as e:
        error_msg = f"åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        print(f"âŒ {error_msg}")
        logger.error(error_msg)
        import traceback
        logger.error(traceback.format_exc())
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… ç³»çµ±æ¸¬è©¦æˆåŠŸï¼æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½é‹è¡Œæ­£å¸¸")
        print("ğŸ’¡ å¦‚éœ€å®Œæ•´å½±ç‰‡åˆæˆï¼Œè«‹ä½¿ç”¨: python main.py")
    else:
        print("\nâŒ ç³»çµ±æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤æ—¥èªŒ")
        sys.exit(1)