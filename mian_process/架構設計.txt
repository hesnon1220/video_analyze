專案描述:
此專案的目的為「輸入影像、音樂、歌詞，自動化生成剪輯影片」
(以專案以F:\work\video_analyze\mian_process為根目錄)

步驟設計:
    1.對影像進行灰階直方圖運算、紀錄變化量  
    2.依照變化量進行畫面分割  
    3.使用影像辨識模型進行畫面挑選  
    4.紀錄畫面色階  
    5.需手動進行歌詞時間軸  
    6.依照時間軸區間進行畫面填充  
    7.使用第三方軟體新增音樂字幕 

架構設計:
1. 影像分析模組 (image_analysis)
    - 功能: 分析輸入的影像素材，提取關鍵畫面和場景變化。
    a. 時序畫面分割
        - 參考程式碼: F:\work\video_analyze\mian_process\old_process\get_3hist.py,F:\work\video_analyze\mian_process\old_process\cut_video.py
        - 概念設計: 使用影像處理技術如色彩直方圖、邊緣檢測等方法來分析影像內容，以「畫面的色直方圖差距超過一定閾值則判定為不同場景段落」且「該場景段落長度超過一定閾值」進行時間點的切割
        - 輸入: 影像檔案
        - 輸出: 場景切割時間點列表
    b. 影像特徵提取
        - 概念設計: 使用預訓練的影像辨識模型(YOLO)來識別影像中的物體和場景、情境分析，並提取相關特徵，連接llm進行更高層次的語義理解
        - 輸入: 影像檔案+場景切割時間點列表
        - 輸出: 影像特徵資料(物體標籤、位置、場景描述等)

2. 音樂處理模組 (music_processing)
    - 功能: 處理輸入的音樂素材，提取節奏和歌詞時間軸。
    a. 音源分離(demucs)
        - 將音樂檔案中的人聲和伴奏分離，方便後續的歌詞對齊。
        - 輸入: 音樂檔案
        - 輸出: 分離後的人聲和伴奏音軌
    b. 節奏分析(需搜尋開源工具)
        - 分析音樂的節奏和強弱變化，提取節拍信息。
        - 輸入: 音樂檔案
        - 輸出: 節拍時間點列表
    c. 歌詞時間軸標註
        - 使用RhythmicaLyrics等工具手動標註歌詞的時間軸。
        - 輸入: 歌詞文本+音樂檔案
        - 輸出: 歌詞時間軸資料

3. 影片生成模組 (video_generation)
    - 功能: 根據影像特徵和歌詞時間軸，自動生成剪輯影片。
    a. 畫面填充
        - 根據歌詞時間軸和影像特徵，選擇合適的畫面進行填充。
        - 輸入: 影像特徵資料+歌詞時間軸資料
        - 輸出: 初步剪輯影片
        - 參考程式碼: F:\work\video_analyze\mian_process\old_process\read_picked_data.py
    b. 字幕添加
        - 使用第三方軟體(如ニコカラメーカー2、aegisub)添加音樂字幕。


其他:
    - 專案管理: 使用Git進行版本控制，確保程式碼的可追溯性和協作開發。
    - 測試與驗證: 建立測試用例，確保各模組功能的正確性和穩定性。
    - 文件撰寫: 撰寫詳細的技術文件、檔案架構和使用說明，方便後續維護和使用。
    - 建立修改歷史文件: 可讓後續llm參考修改過程與思路。
    - 專案root目錄: F:\work\video_analyze\mian_process
    - 其他套件參考:F:\work\video_analyze\mian_process\old_process\Helper_private.py
    - 開發語言: Python
    - 開發環境: Conda虛擬環境"video_analyze" (務必使用該環境安裝相關套件)


目標文件:
 - 影片資料夾: F:\work\video_analyze\data\video\Beelzebub-jou no Okinimesu mama (共9個影片)
 - 音樂檔案: F:\work\video_analyze\data\audio\Beelzebub-jou no Okinimesu Mama\01.ピンクレモネード.mp3 (共1個音樂)
